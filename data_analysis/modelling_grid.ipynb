{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccbf0984-048c-4f95-a921-7a88ce1aea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "Collecting scipy>=1.5.0\n",
      "  Downloading scipy-1.11.2-cp311-cp311-win_amd64.whl (44.0 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\david\\pycharmprojects\\big_data_tfm\\venv\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.0 scipy-1.11.2 threadpoolctl-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.2; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\David\\PycharmProjects\\big_data_tfm\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3c441e63-2ea4-41c7-b3e2-1e066e0bdb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_11860\\233358790.py:5: DtypeWarning: Columns (58,84,96,97) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_all = pd.read_csv(\"pisos.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_all = pd.read_csv(\"pisos.csv\")\n",
    "\n",
    "df_expensive = df_all[df_all['price_euro'] > 350000]\n",
    "df_cheap = df_all[df_all['price_euro'] <= 350000]\n",
    "\n",
    "\n",
    "# categorical_cols = ['title', 'location', 'city', 'description', 'link', 'updated_date',\n",
    "#        'planta', 'referencia', 'carpinteria_exterior', 'garaje', 'trastero',\n",
    "#        'ascensor', 'photos', 'exterior', 'conservacion', 'balcon',\n",
    "#        'armarios_empotrados', 'terraza', 'piscina', 'orientacion',\n",
    "#        'gastos_de_comunidad', 'amueblado',\n",
    "#        'adaptado_a_personas_con_movilidad_reducida', 'tipo_suelo', 'jardin',\n",
    "#        'telefono', 'cocina_equipada', 'comedor', 'portero_automatico',\n",
    "#        'antiguedad', 'carpinteria_interior', 'soleado', 'cocina', 'urbanizado',\n",
    "#        'calle_alumbrada', 'calle_asfaltada', 'agua', 'tipo_de_casa',\n",
    "#        'aire_acondicionado', 'lavadero', 'puerta_blindada', 'interior',\n",
    "#        'se_aceptan_mascotas', 'vidrios_dobles', 'chimenea',\n",
    "#        'sistema_de_seguridad', 'calefaccion', 'gas', 'luz', 'alcantarillado',\n",
    "#        'no_se_aceptan_mascotas', 'exterior_summary', 'vidrios_dobles_summary',\n",
    "#        'adaptado_a_personas_con_movilidad_reducida_summary',\n",
    "#        'puerta_blindada_summary', 'ascensor_summary', 'balcon_summary',\n",
    "#        'portero_automatico_summary', 'garaje_summary', 'comedor_summary',\n",
    "#        'terraza_summary', 'jardin_summary', 'armarios_empotrados_summary',\n",
    "#        'aire_acondicionado_summary', 'trastero_summary', 'piscina_summary',\n",
    "#        'chimenea_summary', 'lavadero_summary', 'urbanizado_summary',\n",
    "#        'calle_alumbrada_summary', 'calle_asfaltada_summary', 'soleado_summary',\n",
    "#        'gas_summary', 'sistema_de_seguridad_summary', 'interior_summary',\n",
    "#        'alcantarillado_summary', 'amueblado_summary',\n",
    "#        'cocina_equipada_summary', 'mascotas_summary',\n",
    "#        'carpinteria_exterior_cleaned', 'tipo_suelo_summary',\n",
    "#        'calefaccion_summary', 'cocina_summary', 'orientacion_summary',\n",
    "#        'agua_summary', 'type', 'esquina', 'esquina_summary']\n",
    "\n",
    "# categorical_clean = ['conservacion', 'antiguedad', 'tipo_de_casa', 'alcantarillado', \n",
    "#                      'exterior_summary', 'vidrios_dobles_summary', 'adaptado_a_personas_con_movilidad_reducida_summary', \n",
    "#                      'puerta_blindada_summary', 'ascensor_summary', 'balcon_summary', 'portero_automatico_summary', \n",
    "#                      'garaje_summary', 'comedor_summary', 'terraza_summary', \n",
    "#                      'jardin_summary', 'armarios_empotrados_summary', 'aire_acondicionado_summary', \n",
    "#                      'trastero_summary', 'piscina_summary', 'chimenea_summary', \n",
    "#                      'lavadero_summary', 'urbanizado_summary', 'calle_alumbrada_summary', \n",
    "#                      'calle_asfaltada_summary', 'soleado_summary', 'gas_summary', \n",
    "#                      'sistema_de_seguridad_summary', 'interior_summary', 'alcantarillado_summary', \n",
    "#                      'amueblado_summary', 'cocina_equipada_summary', 'mascotas_summary', \n",
    "#                      'carpinteria_exterior_cleaned', 'tipo_suelo_summary', 'calefaccion_summary', \n",
    "#                      'cocina_summary', 'orientacion_summary', 'agua_summary', 'gas_summary' \n",
    "                     # 'type', 'esquina_summary']\n",
    "\n",
    "\n",
    "\n",
    "def clean_data(origin_df):\n",
    "    df = origin_df.copy()\n",
    "    categorical_to_fill_NO = ['exterior_summary', 'vidrios_dobles_summary', 'adaptado_a_personas_con_movilidad_reducida_summary',\n",
    "                             'puerta_blindada_summary', 'ascensor_summary', 'balcon_summary', 'portero_automatico_summary',\n",
    "                            'garaje_summary', 'comedor_summary', 'terraza_summary', \n",
    "                            'jardin_summary', 'armarios_empotrados_summary', 'aire_acondicionado_summary', \n",
    "                              'trastero_summary', 'piscina_summary', 'chimenea_summary', \n",
    "                               'lavadero_summary', 'soleado_summary', 'gas_summary',\n",
    "                              'amueblado_summary', 'cocina_equipada_summary', 'calefaccion_summary',\n",
    "                             ]\n",
    "    categorical_to_fill_DESCONOCIDO = ['city', 'location', 'conservacion', 'antiguedad', 'tipo_de_casa', 'urbanizado_summary', \n",
    "                                      'calle_alumbrada_summary', 'calle_asfaltada_summary', 'interior_summary', \n",
    "                                      'mascotas_summary', 'carpinteria_exterior_cleaned', 'tipo_suelo_summary',\n",
    "                                      'cocina_summary', 'orientacion_summary', 'orientacion_summary', \n",
    "                                      'type']\n",
    "    \n",
    "    numerical = ['price_euro', 'old_price_euro', 'superficie_construida_m2', \n",
    "                'superficie_util_m2', 'habitaciones', 'banos', \n",
    "                'superficie_solar_m2', 'gastos_de_comunidad_cleaned']\n",
    "    # Fill NaN values with 'NO' for selected categorical columns\n",
    "    for col in categorical_to_fill_NO:\n",
    "        df[col].fillna('NO', inplace=True)\n",
    "    \n",
    "    for col in categorical_to_fill_DESCONOCIDO:\n",
    "        df[col].fillna('DESCONOCIDO', inplace=True)\n",
    "    \n",
    "    categorical = categorical_to_fill_NO + categorical_to_fill_DESCONOCIDO\n",
    "\n",
    "    df = df[categorical + numerical]\n",
    "\n",
    "    # Create a mask for rows where both columns superficie are not null\n",
    "    mask = df['superficie_util_m2'].notna() & df['superficie_construida_m2'].notna()\n",
    "    # Calculate the percentage difference for these rows\n",
    "    percentage_diffs = (df.loc[mask, 'superficie_construida_m2'] - df.loc[mask, 'superficie_util_m2']) / df.loc[mask, 'superficie_construida_m2']\n",
    "    # Calculate the average percentage\n",
    "    average_percentage = percentage_diffs.mean()\n",
    "    mask = df['superficie_construida_m2'].isna() & df['superficie_util_m2'].notna()\n",
    "    df.loc[mask, 'superficie_construida_m2'] = df.loc[mask, 'superficie_util_m2'] * (1 + average_percentage)\n",
    "    median_value = df['superficie_construida_m2'].median()\n",
    "    df['superficie_construida_m2'].fillna(median_value, inplace=True)\n",
    "    \n",
    "    mask = df['superficie_util_m2'].isna()\n",
    "    df.loc[mask, 'superficie_util_m2'] = df.loc[mask, 'superficie_construida_m2'] * (1 - average_percentage)\n",
    "\n",
    "    df['superficie_solar_m2'].fillna(0, inplace=True)\n",
    "\n",
    "    df.dropna(subset=['price_euro'], inplace=True)\n",
    "    df['old_price_euro'].fillna(df['price_euro'], inplace=True)\n",
    "\n",
    "    def convert_to_cat(val):\n",
    "        if pd.isna(val):\n",
    "            return \"DESCONOCIDO\"\n",
    "        elif val <= 6:\n",
    "            return str(int(val))\n",
    "        else:\n",
    "            return \"7 or more\"\n",
    "    \n",
    "    def convert_gastos(val):\n",
    "        if pd.isna(val):\n",
    "            return \"DESCONOCIDO\"\n",
    "        elif val == 0:\n",
    "            return \"0\"\n",
    "        elif 0 < val <= 20:\n",
    "            return \"0-20\"\n",
    "        elif 20 < val <= 40:\n",
    "            return \"20-40\"\n",
    "        elif 40 < val <= 60:\n",
    "            return \"40-60\"\n",
    "        elif 60 < val <= 80:\n",
    "            return \"60-80\"\n",
    "        elif 80 < val <= 100:\n",
    "            return \"80-100\"\n",
    "        elif 100 < val <= 120:\n",
    "            return \"100-120\"\n",
    "        elif 120 < val <= 140:\n",
    "            return \"120-140\"\n",
    "        elif 140 < val <= 160:\n",
    "            return \"140-160\"\n",
    "        elif 160 < val <= 180:\n",
    "            return \"160-180\"\n",
    "        elif 180 < val <= 200:\n",
    "            return \"180-200\"\n",
    "        elif val > 200:\n",
    "            return \"200+\"\n",
    "    \n",
    "    df['gastos_de_comunidad_cleaned'] = df['gastos_de_comunidad_cleaned'].apply(convert_gastos)\n",
    "    df['habitaciones'] = df['habitaciones'].apply(convert_to_cat)\n",
    "    df['banos'] = df['banos'].apply(convert_to_cat)\n",
    "\n",
    "    nan_counts = df[numerical+categorical].isna().sum()\n",
    "    assert(nan_counts.sum() == 0)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e32b5e14-b666-408d-a88d-e469720b220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26680 140076\n"
     ]
    }
   ],
   "source": [
    "print(len(df_expensive), len(df_cheap))\n",
    "df_cheap = clean_data(df_cheap)\n",
    "df_expensive = clean_data(df_expensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a9e4beed-0288-4323-98d9-575b7b133500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(df, city, model_type):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "    # Define parameter grids for each model type\n",
    "    param_grids = {\n",
    "        \"RandomForest\": {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        \"GradientBoosting\": {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 5, 7, 9],\n",
    "            'subsample': [0.8, 0.9, 1.0]\n",
    "        },\n",
    "        \"AdaBoost\": {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'learning_rate': [0.01, 0.05, 0.1]\n",
    "        },\n",
    "        \"ExtraTrees\": {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        },\n",
    "        \"DecisionTree\": {\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Drop the target and other unwanted columns\n",
    "    X = df.drop(columns=['price_euro', 'old_price_euro'])\n",
    "    \n",
    "    # One-hot encode the categorical columns\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical+['habitaciones','banos','gastos_de_comunidad_cleaned'])\n",
    "    \n",
    "    # Define the target\n",
    "    y = df['price_euro']\n",
    "    \n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    if model_type == \"RandomForest\":\n",
    "        base_model = RandomForestRegressor(random_state=42)\n",
    "    elif model_type == \"GradientBoosting\":\n",
    "        base_model = GradientBoostingRegressor(random_state=42)\n",
    "    elif model_type == \"AdaBoost\":\n",
    "        base_model = AdaBoostRegressor(random_state=42)\n",
    "    elif model_type == \"ExtraTrees\":\n",
    "        base_model = ExtraTreesRegressor(random_state=42)\n",
    "    elif model_type == \"DecisionTree\":\n",
    "        base_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    # Setup GridSearchCV\n",
    "    grid_search = GridSearchCV(base_model, param_grids[model_type], cv=3, n_jobs=-1, verbose=1)\n",
    "    \n",
    "    # Fit the GridSearch\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(f\"Best hyperparameters for {model_type} in {city}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Use the best estimator from GridSearch\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predict using the best model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    def plot_true_to_predicted(y_test, y_pred):\n",
    "        true_values = y_test.tolist()\n",
    "        predicted_values = y_pred.tolist()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(true_values, predicted_values, alpha=0.5)\n",
    "        plt.xlabel(\"True Values\")\n",
    "        plt.ylabel(\"Predicted Values\")\n",
    "        plt.title(f\"True vs. Predicted Values for {city}\")\n",
    "        plt.plot([min(true_values), max(true_values)], \n",
    "                 [min(true_values), max(true_values)], 'r')\n",
    "        plt.show()\n",
    "\n",
    "    feature_importances = best_model.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X_encoded.columns,\n",
    "        'importance': feature_importances\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    print(importance_df)\n",
    "\n",
    "    # Calculate the mean squared error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # Statistics of price_euro\n",
    "    mean_price = df['price_euro'].mean()\n",
    "    std_price = df['price_euro'].std()\n",
    "\n",
    "\n",
    "    return best_model, rmse, mean_price\n",
    "\n",
    "def generate_models(unique_cities, model_type=\"RandomForest\"):\n",
    "\n",
    "    models = {}  # To store trained models for each city\n",
    "    rmse_scores = {}  # To store RMSE scores for each city\n",
    "    mean_prices = {}\n",
    "    \n",
    "    for city in unique_cities:\n",
    "        \n",
    "        city_df_cheap = df_cheap[df_cheap['city'] == city].copy()\n",
    "        \n",
    "        cheap_model, cheap_rmse, cheap_mean_price = create_model(city_df_cheap, city, model_type)\n",
    "        # Store the trained model and RMSE\n",
    "    \n",
    "        print(\"Cheap model -----------\")\n",
    "        print(f\"City: {city}, RMSE: {cheap_rmse:.2f}, mean_price: {cheap_mean_price}\")\n",
    "    \n",
    "        city_df_expensive = df_expensive[df_expensive['city'] == city].copy()\n",
    "        \n",
    "        expensive_model, expensive_rmse, expensive_mean_price = create_model(city_df_expensive, city, model_type)\n",
    "    \n",
    "    \n",
    "        print(\"Expensive model ----------\")\n",
    "        print(f\"City: {city}, RMSE: {expensive_rmse:.2f}, mean_price: {expensive_mean_price}\")\n",
    "    \n",
    "        models[city] = {'cheap': cheap_model, 'expensive': expensive_model}\n",
    "        rmse_scores[city] = {'cheap': cheap_rmse, 'expensive': expensive_rmse}\n",
    "        mean_prices[city] = {'cheap': cheap_mean_price, 'expensive': expensive_mean_price}\n",
    "\n",
    "    rmse_scores_relative = { k: {'cheap': rmse_scores[k]['cheap']/mean_prices[k]['cheap'],\n",
    "                            'expensive': rmse_scores[k]['expensive']/mean_prices[k]['expensive']\n",
    "                            } for k in rmse_scores.keys()}\n",
    "\n",
    "    return rmse_scores_relative, models\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400612a-cdfe-42b7-88b9-ce6c7bdbe8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best hyperparameters for RandomForest in tenerife: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "                                       feature  importance\n",
      "0                     superficie_construida_m2    0.102236\n",
      "1                           superficie_util_m2    0.079626\n",
      "22                         terraza_summary_YES    0.060259\n",
      "21                          terraza_summary_NO    0.051779\n",
      "315                                    banos_1    0.037915\n",
      "..                                         ...         ...\n",
      "132  location_La Cañada (Buenavista del Norte)    0.000000\n",
      "137                   location_La Jaca (Arico)    0.000000\n",
      "141           location_La Perdoma (La Orotava)    0.000000\n",
      "179                   location_Pájara (Güímar)    0.000000\n",
      "167       location_Montero (Icod de Los Vinos)    0.000000\n",
      "\n",
      "[334 rows x 2 columns]\n",
      "Cheap model -----------\n",
      "City: tenerife, RMSE: 51209.69, mean_price: 198173.72724113968\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best hyperparameters for RandomForest in tenerife: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "                                               feature  importance\n",
      "1                                   superficie_util_m2    0.298196\n",
      "83                        location_Costa Adeje (Adeje)    0.221563\n",
      "0                             superficie_construida_m2    0.103000\n",
      "2                                  superficie_solar_m2    0.050674\n",
      "141          location_San Isidro (Granadilla de Abona)    0.039298\n",
      "..                                                 ...         ...\n",
      "109                 location_La Esperanza (El Rosario)    0.000000\n",
      "110                                location_La Guancha    0.000000\n",
      "111                    location_La Matanza de Acentejo    0.000000\n",
      "165  location_Vistabella (Distrito Ofra-Costa Sur. ...    0.000000\n",
      "155           location_Tejina de Isora (Guía de Isora)    0.000000\n",
      "\n",
      "[280 rows x 2 columns]\n",
      "Expensive model ----------\n",
      "City: tenerife, RMSE: 612620.37, mean_price: 924522.5831889082\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best hyperparameters for RandomForest in lleida: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "                        feature  importance\n",
      "345                     banos_1    0.169625\n",
      "1            superficie_util_m2    0.096580\n",
      "0      superficie_construida_m2    0.075819\n",
      "347                     banos_3    0.025878\n",
      "2           superficie_solar_m2    0.025858\n",
      "..                          ...         ...\n",
      "146             location_L'Albi    0.000000\n",
      "151         location_La Fuliola    0.000000\n",
      "179              location_Navès    0.000000\n",
      "90   location_Bellmunt d'Urgell    0.000000\n",
      "184           location_Penelles    0.000000\n",
      "\n",
      "[363 rows x 2 columns]\n",
      "Cheap model -----------\n",
      "City: lleida, RMSE: 45087.44, mean_price: 125114.37211686315\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best hyperparameters for RandomForest in lleida: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "                               feature  importance\n",
      "78              location_Escàs (Rialp)    0.208655\n",
      "1                   superficie_util_m2    0.196720\n",
      "2                  superficie_solar_m2    0.192953\n",
      "0             superficie_construida_m2    0.058874\n",
      "161         tipo_suelo_summary_PARQUET    0.027243\n",
      "..                                 ...         ...\n",
      "122  location_Vilac (Vielha e Mijaran)    0.000000\n",
      "121   location_Vila (Vielha e Mijaran)    0.000000\n",
      "74       location_El Palau d'Anglesola    0.000000\n",
      "118          location_Unha (Naut Aran)    0.000000\n",
      "113                   location_Solsona    0.000000\n",
      "\n",
      "[226 rows x 2 columns]\n",
      "Expensive model ----------\n",
      "City: lleida, RMSE: 387566.16, mean_price: 726578.3005464481\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best hyperparameters for RandomForest in fuerteventura: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "                                       feature  importance\n",
      "0                     superficie_construida_m2    0.292348\n",
      "1                           superficie_util_m2    0.105088\n",
      "59               location_Corralejo (La Oliva)    0.092801\n",
      "189                                    banos_1    0.058161\n",
      "2                          superficie_solar_m2    0.043453\n",
      "..                                         ...         ...\n",
      "79          location_Nuevo Horizonte (Antigua)    0.000000\n",
      "179                                  type_loft    0.000000\n",
      "133                 tipo_suelo_summary_TERRAZO    0.000000\n",
      "67   location_Enlace de La Entallada (Tuineje)    0.000000\n",
      "72                 location_La Lajita (Pájara)    0.000000\n",
      "\n",
      "[206 rows x 2 columns]\n",
      "Cheap model -----------\n",
      "City: fuerteventura, RMSE: 39331.26, mean_price: 186508.1372141372\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best hyperparameters for RandomForest in fuerteventura: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "                                     feature  importance\n",
      "1                         superficie_util_m2    0.278727\n",
      "175                          banos_7 or more    0.228083\n",
      "0                   superficie_construida_m2    0.144785\n",
      "167                   habitaciones_7 or more    0.064776\n",
      "2                        superficie_solar_m2    0.060611\n",
      "..                                       ...         ...\n",
      "67                location_La Mata (Tuineje)    0.000000\n",
      "66   location_La Corte Tiscamanita (Antigua)    0.000000\n",
      "65             location_Juan Gopar (Tuineje)    0.000000\n",
      "64           location_Gran Tarajal (Tuineje)    0.000000\n",
      "182  gastos_de_comunidad_cleaned_DESCONOCIDO    0.000000\n",
      "\n",
      "[183 rows x 2 columns]\n",
      "Expensive model ----------\n",
      "City: fuerteventura, RMSE: 221800.79, mean_price: 637807.4628378379\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "def get_best_models(rmse_results):\n",
    "    \"\"\"\n",
    "    Determine the best model for each city and category based on RMSE.\n",
    "\n",
    "    rmse_results: Nested dictionary where the first key is model type, \n",
    "                  the second key is city name, and the value is a dictionary \n",
    "                  with 'cheap' and 'expensive' RMSEs.\n",
    "    \"\"\"\n",
    "    best_models = {}\n",
    "    \n",
    "    for city in rmse_results[next(iter(rmse_results))].keys():  # use next(iter()) to get the first model type\n",
    "        best_models[city] = {\n",
    "            \"cheap\": min([(model, data[city]['cheap']) for model, data in rmse_results.items()], key=lambda x: x[1]),\n",
    "            \"expensive\": min([(model, data[city]['expensive']) for model, data in rmse_results.items()], key=lambda x: x[1])\n",
    "        }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Main code\n",
    "model_types = [\"RandomForest\", \"GradientBoosting\", \"AdaBoost\", \"ExtraTrees\", \"DecisionTree\"]\n",
    "rmse_results_all_models = {}\n",
    "\n",
    "for model_type in model_types:\n",
    "    rmse_scores_relative, models = generate_models(unique_cities=df_all['city'].unique(), model_type=model_type)\n",
    "    rmse_results_all_models[model_type] = rmse_scores_relative\n",
    "\n",
    "best_models_for_each_city = get_best_models(rmse_results_all_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b4fce7-f882-438e-a758-8ac105fd6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the results:\n",
    "for city, models in best_models_for_each_city.items():\n",
    "    print(f\"City: {city}\")\n",
    "    print(f\"Best Cheap Model: {models['cheap'][0]} with RMSE of {models['cheap'][1]:.4f}\")\n",
    "    print(f\"Best Expensive Model: {models['expensive'][0]} with RMSE of {models['expensive'][1]:.4f}\")\n",
    "    print(\"------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
